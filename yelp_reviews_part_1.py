# -*- coding: utf-8 -*-
"""Yelp_Reviews_Part 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uPY3WSqC5cmLL4cchhN0gqMJzbjxm7Es
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Preparation Work

## Load Python Settings and Packages
"""

# suppress warnings
import warnings;
warnings.filterwarnings("ignore");

# common imports
import pandas as pd
import numpy as np
import re
import glob
import os
import random
import pprint as pp
import html
import nltk
import json

from tqdm.auto import tqdm
# register pandas
tqdm.pandas()

import matplotlib
from matplotlib import pyplot as plt

import seaborn as sns
sns.set_style("darkgrid")

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.pipeline import Pipeline

"""## Change the working directory and load train dataset"""

# change to current directory
BASE_DIR = "/content/drive/MyDrive/Yifei_Master_Paper"
os.chdir(BASE_DIR)

path = "./yelp_academic_dataset_review.json"

data=[]
with open(path, 'r', encoding='utf-8') as f:
    for i, line in enumerate(f):
        if i >= 100000:  # only pick 100K data as our dataset
            break
        data.append(json.loads(line))

df = pd.DataFrame(data)
df.info()

# drop unnecessary columns
df = df.drop(['review_id', 'user_id', 'business_id', 'useful', 'funny', 'cool', 'date'], axis=1)
df.info()

"""## Language detection"""

!pip install langid swifter

import langid
import swifter

# detect languages
def lang_detect(text):
    if not isinstance(text, str) or len(text.strip()) < 2:
        return "unknown"
    try:
        return langid.classify(text)[0]
    except:
        return "error"

df['lang'] = df['text'].swifter.progress_bar(True).apply(lang_detect)

# show different languages

df['lang'].value_counts(ascending=False)

df['lang'].nunique()

# only keep data in english

df = df[df['lang'] == 'en'].reset_index(drop=True)
df.to_csv("yelp_english.csv", index=False)

df.head(5)

df.drop(columns=['lang'],inplace=True)

df.head()

"""# Exploratory Data Analysis

"""

df.shape

# check fisrt 5 rows
display(df.head())

display(df.describe().T)

# check categories of each column
df.nunique()

df.duplicated().sum()

df = df.drop_duplicates()
print(df.duplicated().sum())
print("shape without duplicates:",df.shape)

df.isnull().sum()

df.stars.value_counts().sort_index()

df.stars.value_counts().plot(kind='bar');

df.stars.value_counts().sort_index().plot(kind='bar');

df.stars.value_counts(normalize=True).sort_index()

# calculate the length of each text
df['length'] = df['text'].str.len()
df.describe().T

# boxplot of length
df['length'].plot(kind='box',vert=False,figsize=(12,1));

# histplot of length
df['length'].plot(kind='hist',bins=30,figsize=(12,4))

"""right-skewed distribution: many outliers in the right side/existing of extra long text"""

# histplot of length
plt.figure(figsize=(12,4))
sns.histplot(df['length'],bins=30,kde=True,stat='density')
plt.show()

"""## Cleaning, Tokenization and Removing stop words"""

# define a cleaning function

def clean(text):
    # convert html escapes like &amp; to characters.
    text = html.unescape(text)
    # tags like <tab>
    text = re.sub(r'<[^<>]*>', ' ', text)
    # markdown URLs like [Some text](https://....)
    text = re.sub(r'\[([^\[\]]*)\]\([^\(\)]*\)', r'\1', text)
    # text or code in brackets like [0]
    text = re.sub(r'\[[^\[\]]*\]', ' ', text)
    # standalone sequences of specials, matches &# but not #cool
    text = re.sub(r'(?:^|\s)[&#<>{}\[\]+|\\:-]{1,}(?:\s|$)', ' ', text) #look around the sequence of interest  "^" & "$" stands resp. for beginning and end of a line or string "?:" stands for "look around but don't capture"
    # standalone sequences of hyphens like --- or ==
    text = re.sub(r'(?:^|\s)[\-=\+]{2,}(?:\s|$)', ' ', text)
    # sequences of white spaces
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

df['text'] = df['text'].progress_apply(clean)

# define a tokenization function by regular expression
import regex as re

def tokenize(text):
    pattern = r"""
        (?:[A-Za-z]\.){2,}          # abbreviations
        | \#\w+               # hashtags
        | \@\w+               # user names
        | [A-Za-z]+(?:['-][A-Za-z]+)*    # words, including hyphenated or apostrophized forms
        | \d+(?:\.\d+)?%?          # numbers or percentages
        | [\p{So}\p{Sk}]           # emoji and special Unicode symbols
    """
    tokens = re.findall(pattern, text, re.VERBOSE)
    return tokens

nltk.download('stopwords')

stopwords = set(nltk.corpus.stopwords.words('english'))

def remove_stop(tokens):
  return [t for t in tokens if t.lower() not in stopwords]

pipeline = [str.lower, tokenize, remove_stop]

def prepare(text,pipeline):
  tokens = text
  for transform in pipeline:
    tokens = transform(tokens)
  return tokens

df['tokens'] = df['text'].progress_apply(prepare,pipeline=pipeline)

df['num_of_tokens'] = df['tokens'].progress_apply(len)
df.head()

df[df['tokens'].apply(len) == 0]

df = df[df['tokens'].apply(len) > 0].reset_index(drop=True)

df.head()

"""## word frequency analysis"""

# calculate word frequency

from collections import Counter
counter = Counter()
_ = df['tokens'].map(counter.update)

df_most_common = pd.DataFrame(counter.most_common(10),columns=['word','count'])
df_most_common

def count_words(df,column='tokens',preprocess=None, min_freq=2):
  def update(doc):
    tokens = doc if preprocess is None else preprocess(doc)
    counter.update(tokens)

  counter = Counter()
  df[column].progress_apply(update)

  freq_df = pd.DataFrame.from_dict(counter, orient='index',columns=['freq'])
  freq_df = freq_df.query('freq>=@min_freq')
  freq_df.index.name = 'token'

  return freq_df.sort_values('freq',ascending=False)

freq_df = count_words(df,column='tokens', preprocess=None, min_freq=2)
freq_df.head(10)

ax = freq_df.head(10).plot.barh(width=1, figsize=(12,3))
ax.invert_yaxis()
ax.set(xlabel='Frequency',ylabel='token',title='Top 10 words');

"""## Word clouds"""

from wordcloud import WordCloud

def wordcloud(word_freq, title=None, max_words=200, stopwords=None):

  wc = WordCloud(width=1000, height=500,
                  background_color= "black", colormap="Paired",
                  max_font_size=150, max_words=max_words)

  # convert data frame into dict
  if type(word_freq) == pd.Series:
      counter = Counter(word_freq.fillna(0).to_dict())
  else:
      counter = word_freq

  # filter stop words in frequency counter
  if stopwords is not None:
      counter = {token:freq for (token, freq) in counter.items()
                            if token not in stopwords}
  wc.generate_from_frequencies(counter)

  plt.title(title)
  plt.imshow(wc, interpolation='bilinear')
  plt.axis("off")
  plt.show()

plt.figure(figsize=(10,4))
wordcloud(freq_df['freq'],max_words=100)

"""## TF-IDF Rank"""

def compute_idf(df, column='tokens', preprocess=None, min_df=2):
  def update(doc):
    tokens = doc if preprocess is None else preprocess(doc)
    counter.update(set(tokens))

  # count tokens
  counter = Counter()
  df[column].progress_map(update)

  # create data frame and compute idf
  idf_df = pd.DataFrame.from_dict(counter, orient='index', columns=['df'])
  idf_df = idf_df.query('df >= @min_df')
  idf_df['idf'] = np.log(len(df)/idf_df['df'])+0.1
  idf_df.index.name = 'token'
  return idf_df

idf_df = compute_idf(df, column='tokens', preprocess=None, min_df=2)

idf_df.sample(5,random_state=42)

# calculate tfidf

freq_df = freq_df.merge(idf_df, left_index=True, right_index=True, how='left')
freq_df['tfidf'] = freq_df['freq'] * freq_df['idf']

freq_df.head(5)

freq_df.sample(5,random_state=10)

freq_df.head(15).sort_values('tfidf',ascending=False)

ax = freq_df[['tfidf']].head(50).sort_values('tfidf',ascending=False).plot.barh(width=1,figsize=(12,8))
ax.invert_yaxis()
ax.set(xlabel='TF-IDF',ylabel='token',title='Top 50 words by TF-IDF');

"""# Traditional machine learning models

## Train Test Split
"""

df.sample(3)

# split dataset

train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['stars'],random_state=42)

X_train,y_train = train_df['tokens'],train_df['stars']
X_test,y_test = test_df['tokens'],test_df['stars']

"""## Vectorization - TfidfVectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer

# design the vectorizer
TfidfVectorizer = TfidfVectorizer(
    tokenizer=lambda x: x,       # inputs are tokens
    preprocessor=lambda x: x,    # no preprocessing
    token_pattern=None,
    analyzer='word',
    max_features=20000,
    ngram_range=(1, 2)
)

X_train_tfidf = TfidfVectorizer.fit_transform(X_train)
X_test_tfidf = TfidfVectorizer.transform(X_test)

type(X_train_tfidf)

"""## Logistic Regression"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# logistic_reg = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)
# logistic_reg.fit(X_train_tfidf, y_train)

from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score

y_pred = logistic_reg.predict(X_test_tfidf)
y_pred_proba = logistic_reg.predict_proba(X_test_tfidf)

print("Accuracy Score：", accuracy_score(y_test,y_pred))
print("ROC-AUC Score：", roc_auc_score(y_test,y_pred_proba,multi_class='ovr'))
print('\n',classification_report(y_test,y_pred))

from sklearn.metrics import confusion_matrix

print(confusion_matrix(y_test,y_pred))

from sklearn.preprocessing import label_binarize

# get classes
classes = np.unique(y_test)

# binarize to one-vs-rest
y_test_bin = label_binarize(y_test, classes=classes)
n_classes = len(classes)

from sklearn.metrics import roc_curve, auc, precision_recall_curve

def plot_roc_auc(y_test_bin, y_pred_proba,classes):

  for i in range(n_classes):
      class_label = classes[i]

      # ROC-AUC curve
      fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
      roc_auc = auc(fpr, tpr)

      plt.figure(figsize=(5,5))
      plt.plot(fpr, tpr, label=f"ROC-AUC = {roc_auc:.4f}")
      plt.plot([0, 1], [0, 1], 'k--')
      plt.xlabel("False Positive Rate")
      plt.ylabel("True Positive Rate")
      plt.title(f"ROC-AUC Curve - Class {class_label}")
      plt.legend()
      plt.show()

plot_roc_auc(y_test_bin, y_pred_proba, classes)

# show PR-AUC curve

def plot_pr_auc(y_test_bin, y_pred_proba,classes):

  for i in range(n_classes):
      class_label = classes[i]

      precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_pred_proba[:, i])
      pr_auc = auc(recall, precision)

      plt.figure(figsize=(5,5))
      plt.plot(recall, precision, label=f"PR-AUC = {pr_auc:.4f}")
      plt.xlabel("Recall")
      plt.ylabel("Precision")
      plt.title(f"PR-AUC Curve - Class {class_label}")
      plt.legend()
      plt.show()

plot_pr_auc(y_test_bin, y_pred_proba, classes)

# calculate overall PR-AUC score

print("PR-AUC Score: ", average_precision_score(y_test_bin,y_pred_proba,average='macro'))

# find the best threshold for each class

def find_best_thresholds(y_test_bin, y_pred_proba, classes):

    best_thresholds = {}

    for i in range(n_classes):
        precision, recall, thresholds = precision_recall_curve(y_test_bin[:, i], y_pred_proba[:, i])

        f1 = 2 * precision * recall / (precision + recall + 1e-8)
        best_idx = np.argmax(f1)

        best_threshold = thresholds[best_idx]
        best_thresholds[classes[i]] = best_threshold

        print(f"Class {classes[i]} | best threshold = {best_threshold:.4f} | F1={f1[best_idx]:.4f}")

    return best_thresholds

best_thresholds = find_best_thresholds(y_test_bin, y_pred_proba, classes)

# set new logic for prediction

def predict(y_pred_proba, thresholds, classes):
    preds = []
    for row in y_pred_proba:
        result = []

        # find classes >= threshold
        for i, cls in enumerate(classes):
            if row[i] >= thresholds[cls]:
                result.append((cls, row[i]))

        # otherwise, use argmax
        if len(result) == 0:
            preds.append(classes[np.argmax(row)])

        # if more classes, choose the max one
        else:
            preds.append(max(result, key=lambda x: x[1])[0])

    return np.array(preds)

y_pred_new = predict(y_pred_proba, best_thresholds, classes)

print("Accuracy Score：", accuracy_score(y_test,y_pred_new))
print('\n',classification_report(y_test,y_pred_new))

"""We can see that despite we have selected the best classification threshold for each category; the new predictions show quite little improvement in performance. We infer that the predicted results do not change more, because many probabilities do not exceed their threshold."""

from sklearn.metrics.pairwise import cosine_similarity
import seaborn as sns

# turn to dense matrix
X_dense = X_test_tfidf.toarray()
labels = np.array(y_test)

# calculate centorids
classes = np.unique(labels)
centroids = np.array([X_dense[labels == c].mean(axis=0) for c in classes])

# calculate cosine similarity
class_sim = cosine_similarity(centroids)
df_sim = pd.DataFrame(class_sim, index=classes, columns=classes)

# heatmap
plt.figure(figsize=(10, 10))
sns.heatmap(df_sim, annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Semantic Heatmap (TF-IDF + Logistic Regression)")
plt.xlabel("Class")
plt.ylabel("Class")
plt.show()

"""---"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# balanced_logistic_reg = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1, class_weight='balanced')
# balanced_logistic_reg.fit(X_train_tfidf, y_train)

y_pred = balanced_logistic_reg.predict(X_test_tfidf)
y_pred_proba = balanced_logistic_reg.predict_proba(X_test_tfidf)

print("Accuracy Score：", accuracy_score(y_test,y_pred))
print("ROC-AUC Score：", roc_auc_score(y_test,y_pred_proba,multi_class='ovr'))
print(classification_report(y_test,y_pred))

"""## LinearSVC"""

from sklearn.svm import SVC
from sklearn.svm import LinearSVC

balanced_linear_svc = LinearSVC(random_state=42,class_weight='balanced')
balanced_linear_svc.fit(X_train_tfidf,y_train)

y_pred = balanced_linear_svc.predict(X_test_tfidf)
y_score = balanced_linear_svc.decision_function(X_test_tfidf)
y_score_prob = (y_score - y_score.min(axis=1, keepdims=True))
y_pred_prob = y_score_prob / y_score_prob.sum(axis=1, keepdims=True)

print("Accuracy Score：", accuracy_score(y_test,y_pred))
print("ROC-AUC Score：", roc_auc_score(y_test,y_pred_prob,multi_class='ovr'))
print(classification_report(y_test,y_pred))

print(confusion_matrix(y_test,y_pred))

plot_roc_auc(y_test_bin, y_pred_proba, classes)

plot_pr_auc(y_test_bin, y_pred_proba, classes)

print("PR-AUC Score: ", average_precision_score(y_test_bin,y_pred_proba,average='macro'))

best_thresholds = find_best_thresholds(y_test_bin, y_pred_proba, classes)

y_pred_new = predict(y_pred_proba, best_thresholds, classes)

print("Accuracy Score：", accuracy_score(y_test,y_pred_new))
print('\n',classification_report(y_test,y_pred_new))

"""## Random Forest"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# random_forest = RandomForestClassifier(
#     n_estimators=100,
#     max_depth=30,
#     random_state=42,
#     n_jobs=-1)
# random_forest.fit(X_train_tfidf,y_train)

y_pred = random_forest.predict(X_test_tfidf)
y_pred_proba = random_forest.predict_proba(X_test_tfidf)

print('Accuracy Score：', accuracy_score(y_test,y_pred))
print('ROC-AUC Score：', roc_auc_score(y_test,y_pred_proba,multi_class='ovr'))
print(classification_report(y_test,y_pred))

print(confusion_matrix(y_test,y_pred))

plot_roc_auc(y_test_bin, y_pred_proba, classes)

plot_pr_auc(y_test_bin, y_pred_proba, classes)

print('PR-AUC Score: ', average_precision_score(y_test_bin,y_pred_proba,average='macro'))

best_thresholds = find_best_thresholds(y_test_bin, y_pred_proba, classes)

y_pred_new = predict(y_pred_proba, best_thresholds, classes)

print('Accuracy Score：', accuracy_score(y_test,y_pred_new))
print('\n',classification_report(y_test,y_pred_new))

"""## Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier

gradient_boosting = GradientBoostingClassifier(n_estimators=50,max_depth=3,random_state=42)

gradient_boosting.fit(X_train_tfidf,y_train)

y_pred = gradient_boosting.predict(X_test_tfidf)
y_pred_proba = gradient_boosting.predict_proba(X_test_tfidf)

print('Accuracy Score：', accuracy_score(y_test,y_pred))
print('ROC-AUC Score：', roc_auc_score(y_test,y_pred_proba,multi_class='ovr'))
print(classification_report(y_test,y_pred))

print(confusion_matrix(y_test,y_pred))

plot_roc_auc(y_test_bin, y_pred_proba, classes)

plot_pr_auc(y_test_bin, y_pred_proba, classes)

print('PR-AUC Score: ', average_precision_score(y_test_bin,y_pred_proba,average='macro'))

best_thresholds = find_best_thresholds(y_test_bin, y_pred_proba, classes)

y_pred_new = predict(y_pred_proba, best_thresholds, classes)

print('Accuracy Score：', accuracy_score(y_test,y_pred_new))
print('\n',classification_report(y_test,y_pred_new))

"""## XGBoost"""

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
y_train_encoded = encoder.fit_transform(y_train)
y_test_encoded = encoder.transform(y_test)

from xgboost import XGBClassifier

xgb = XGBClassifier(
    n_estimators=100,
    max_depth=3,
    objective='multi:softprob',
    num_class=5,
    random_state=42,
    n_jobs=-1
)

xgb.fit(X_train_tfidf,y_train_encoded)

y_pred_new = xgb.predict(X_test_tfidf)
y_pred = encoder.inverse_transform(y_pred_new)
y_pred_proba = xgb.predict_proba(X_test_tfidf)

print('Accuracy Score：', accuracy_score(y_test,y_pred))
print('ROC-AUC Score：', roc_auc_score(y_test,y_pred_proba,multi_class='ovr'))
print(classification_report(y_test,y_pred))

print(confusion_matrix(y_test,y_pred))

plot_roc_auc(y_test_bin, y_pred_proba, classes)

plot_pr_auc(y_test_bin, y_pred_proba, classes)

print('PR-AUC Score: ', average_precision_score(y_test_bin,y_pred_proba,average='macro'))

best_thresholds = find_best_thresholds(y_test_bin, y_pred_proba, classes)

y_pred_new = predict(y_pred_proba, best_thresholds, classes)

print('Accuracy Score：', accuracy_score(y_test, y_pred_new))
print('\n',classification_report(y_test, y_pred_new))

"""## LightGBM"""

from lightgbm import LGBMClassifier

lgbm = LGBMClassifier(
    n_estimators=100,
    max_depth=3,
    random_state=4,
    n_jobs=-1,
    )

lgbm.fit(X_train_tfidf,y_train)

y_pred = lgbm.predict(X_test_tfidf)
y_pred_proba = lgbm.predict_proba(X_test_tfidf)

print('Accuracy Score：', accuracy_score(y_test,y_pred))
print('ROC-AUC Score：', roc_auc_score(y_test,y_pred_proba,multi_class='ovr'))
print(classification_report(y_test,y_pred))

print(confusion_matrix(y_test,y_pred))

plot_roc_auc(y_test_bin, y_pred_proba, classes)

plot_pr_auc(y_test_bin, y_pred_proba, classes)

print('PR-AUC Score: ', average_precision_score(y_test_bin,y_pred_proba,average='macro'))

best_thresholds = find_best_thresholds(y_test_bin, y_pred_proba, classes)

y_pred_new = predict(y_pred_proba, best_thresholds, classes)

print('Accuracy Score：', accuracy_score(y_test,y_pred_new))
print('\n',classification_report(y_test,y_pred_new))

"""# Transformer-based models"""

df.head()

"""## Load pretrained models"""

pip install transformers

from transformers import AutoTokenizer, AutoModelForSequenceClassification

# load tokenizer and model from transformers

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
bert_model= AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=5)

"""## Train-Val-Test Split"""

df.describe()

# prepare test dataset, which accounts for 10%

X_train_original, X_test, y_train_original, y_test = train_test_split(
              df['text'].astype(str),
              df['stars'],
              test_size=0.2,
              random_state=42,
              stratify=df['stars'])

# get training and validation datasets

X_train, X_val, y_train, y_val = train_test_split(
    X_train_original,
    y_train_original,
    test_size=0.1,
    random_state=42,
    stratify=y_train_original)

"""## Embeddings"""

# define a function to get embeddings

def get_tokens(texts, tokenizer, max_len=128):

    return tokenizer(
        texts,
        padding="max_length",       # pad to the max length
        truncation=True,            # truncate extra long text
        max_length=max_len,
        return_tensors="pt"         # return tensors
    )

train_embedding = get_tokens(X_train.astype(str).tolist(), tokenizer, max_len=128)
val_embedding = get_tokens(X_val.astype(str).tolist(), tokenizer, max_len=128)
test_embedding  = get_tokens(X_test.astype(str).tolist(), tokenizer, max_len=128)

"""## Dataset & DataLoader"""

import torch
from torch.utils.data import TensorDataset, DataLoader

# encode labels
encoder = LabelEncoder()
y_train_encode = encoder.fit_transform(y_train)
y_val_encode = encoder.transform(y_val)
y_test_encode = encoder.transform(y_test)

# build datasets

train_dataset = TensorDataset(
    train_embedding['input_ids'],
    train_embedding['attention_mask'],
    torch.tensor(y_train_encode)
)

val_dataset = TensorDataset(
    val_embedding['input_ids'],
    val_embedding['attention_mask'],
    torch.tensor(y_val_encode)
)

test_dataset = TensorDataset(
    test_embedding['input_ids'],
    test_embedding['attention_mask'],
    torch.tensor(y_test_encode))

# DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)
test_loader = DataLoader(test_dataset, batch_size=16)

"""## Optimizer & Scheduler"""

from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup

# hyperparameters
epochs = 3
learning_rate = 2e-6
epsilon = 1e-8
warmup_ratio = 0.1

# steps
t_total = len(train_loader) * epochs
warmup_steps = int(t_total * warmup_ratio)

# optimizer
optimizer = AdamW(bert_model.parameters(),lr=learning_rate,eps=epsilon)

# shceduler
scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=warmup_steps,
    num_training_steps=t_total
)

print(f"Total steps: {t_total}, Warmup steps: {warmup_steps}")

"""## Training"""

from tqdm.notebook import tqdm
from tqdm import trange
from torch.nn.utils import clip_grad_norm_

# send to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bert_model.to(device)

for epoch in trange(epochs):
    bert_model.train()
    total_loss = 0.0

    # show the progress bar
    progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}", leave=True)

    for step, batch in enumerate(progress_bar):
        optimizer.zero_grad()

        # send to GPU
        batch = tuple(t.to(device) for t in batch)

        inputs = {
            'input_ids': batch[0],
            'attention_mask': batch[1],
            'labels': batch[2]
        }

        # forward propagation
        outputs = bert_model(**inputs)
        loss = outputs.loss

        # back propagation
        loss.backward()

        # clip gradients
        clip_grad_norm_(bert_model.parameters(), max_norm=1.0)

        # update parameters
        optimizer.step()

        # update scheduler
        scheduler.step()

        # calculate total loss
        total_loss += loss.item()

        # update progress bar
        progress_bar.set_postfix({"Batch Loss": f"{loss.item():.4f}"})

    # calculate average loss and show
    avg_epoch_loss = total_loss / len(train_loader)
    print(f"\nEpoch {epoch+1} | Average Training Loss: {avg_epoch_loss:.4f}")

# save the model
output_dir = "outputs/bert_ce"
tokenizer.save_pretrained(output_dir)
bert_model.save_pretrained(output_dir)

"""## Validation"""

# define a validation function

def validation(model, dataloader, device):
    model.eval()

    preds = []
    probs = []
    labels = []

    with torch.no_grad():
        for batch in dataloader:
            batch = [t.to(device) for t in batch]
            inputs = {
                'input_ids': batch[0],
                'attention_mask': batch[1]
            }
            outputs = model(**inputs)

            logits = outputs.logits
            prob = torch.softmax(logits, dim=1)

            probs.append(prob.cpu().numpy())
            preds.append(torch.argmax(prob, dim=1).cpu().numpy())
            labels.append(batch[2].cpu().numpy())

    return (
        np.concatenate(labels),
        np.concatenate(preds),
        np.concatenate(probs),
    )

# load the model

from transformers import BertTokenizer, BertForSequenceClassification

model_path = "outputs/bert_ce"
bert_model = BertForSequenceClassification.from_pretrained(model_path).to(device)
tokenizer = BertTokenizer.from_pretrained(model_path)

y_true, y_pred, y_pred_proba = validation(bert_model, val_loader, device)

print("Accuracy:", accuracy_score(y_true, y_pred))
print(classification_report(y_true, y_pred))

classes = sorted(np.unique(y_true))
y_val_bin = label_binarize(y_true, classes=classes)

plot_roc_auc(y_val_bin, y_pred_proba, classes)

"""Macro average ROC-AUC score : 0.90"""

plot_pr_auc(y_val_bin, y_pred_proba, classes)

"""Macro average PR-AUC score : 0.64"""

best_thresholds = find_best_thresholds(y_val_bin, y_pred_proba, classes)

y_pred_new = predict(y_pred_proba, best_thresholds, classes)

print("New Accuracy:", accuracy_score(y_true, y_pred_new))
print(classification_report(y_true, y_pred_new))



"""## Embedding Visualization"""

# define a function to extract embeddings for visualization

def extract_embeddings(model, dataloader, device):
    model.eval()
    embeddings = []
    labels = []

    with torch.no_grad():
        for batch in dataloader:
            batch = [t.to(device) for t in batch]
            input_ids, attention_mask, label = batch

            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                output_hidden_states=True
            )

            # choose the CLS of the final layer
            last_hidden = outputs.hidden_states[-1]
            cls_emb = last_hidden[:, 0, :].cpu().numpy()

            embeddings.append(cls_emb)
            labels.append(label.cpu().numpy())

    embeddings = np.concatenate(embeddings, axis=0)
    labels = np.concatenate(labels, axis=0)

    return embeddings, labels

embeddings, labels = extract_embeddings(bert_model, val_loader, device)

print('Embeddings: ',embeddings.shape)
print('Labels: ',labels.shape)

# use PCA to reduce dimension firstly, because current dimension is 768, very high

from sklearn.decomposition import PCA

pca_ce = PCA(n_components=50).fit_transform(embeddings)

# use UMAP to reduce to 2 dimensions

import umap.umap_ as umap

umap_ce = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1).fit_transform(pca_ce)

plt.figure(figsize=(10,10))

for cls in np.unique(labels):
    idx = labels == cls
    plt.scatter(umap_ce[idx,0], umap_ce[idx,1], s=10, alpha=0.7, label=str(cls))

plt.legend()
plt.title("Visualization of BERT Embeddings")
plt.show()

"""# Weighted CE"""

bert_model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=5).to(device)

# hyperparameters
epochs = 3
learning_rate = 2e-6
epsilon = 1e-8
warmup_ratio = 0.1

# steps
t_total = len(train_loader) * epochs
warmup_steps = int(t_total * warmup_ratio)

# optimizer
optimizer = AdamW(bert_model.parameters(),lr=learning_rate,eps=epsilon)

# shceduler
scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=warmup_steps,
    num_training_steps=t_total
)

print(f"Total steps: {t_total}, Warmup steps: {warmup_steps}")

from collections import Counter

# calculate sample numbers of each class
label_counts = Counter(train_dataset.tensors[2].cpu().numpy())
samples_per_class = [label_counts[i] for i in range(len(label_counts))]

print("Samples per class:", samples_per_class)

samples_per_class = torch.tensor([7853, 5748, 8175, 18206, 31910], dtype=torch.float)

# compute weights and normalization
class_weights = 1.0 / samples_per_class
class_weights = class_weights / class_weights.sum() * len(samples_per_class)

class_weights = class_weights.to(device)

print("Class weights:", class_weights)

# loss function
import torch.nn as nn

criterion = nn.CrossEntropyLoss(weight=class_weights)

for epoch in range(epochs):
    bert_model.train()
    total_loss = 0.0

    # show progress bar
    progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}", leave=True)

    for step, batch in enumerate(progress_bar):
        optimizer.zero_grad()

        # send to GPU
        batch = tuple(t.to(device) for t in batch)
        input_ids, attention_mask, labels = batch

        # forward propagation
        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits if hasattr(outputs, "logits") else outputs[1]

        # compute loss with weighted CE
        loss = criterion(logits, labels)
        total_loss += loss.item()

        # backward propagation
        loss.backward()

        # clip gradients
        clip_grad_norm_(bert_model.parameters(), max_norm=1.0)

        # update parameters and scheduler
        optimizer.step()
        scheduler.step()

        # update progress bar
        if step % 50 == 0:
            progress_bar.set_postfix({"Batch Loss": f"{loss.item():.4f}"})

    # calculate average loss
    avg_epoch_loss = total_loss / len(train_loader)
    print(f"\nEpoch {epoch+1}/{epochs} | Average Training Loss: {avg_epoch_loss:.4f}\n")

# save the model
output_dir = "outputs/bert_weighted_ce"
bert_model.save_pretrained(output_dir)
tokenizer.save_pretrained(output_dir)

model_path = "outputs/bert_weighted_ce"

bert_model = BertForSequenceClassification.from_pretrained(model_path).to(device)
tokenizer = BertTokenizer.from_pretrained(model_path)

y_true, y_pred, y_pred_proba = validation(bert_model, val_loader, device)

print("Accuracy:", accuracy_score(y_true, y_pred))
print(classification_report(y_true, y_pred))

embeddings, labels = extract_embeddings(bert_model, val_loader, device)

pca = PCA(n_components=50).fit_transform(embeddings)

umap_weightedCE = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1).fit_transform(pca)

plt.figure(figsize=(10,10))

for cls in np.unique(labels):
    idx = labels == cls
    plt.scatter(umap_weightedCE[idx,0], umap_weightedCE[idx,1], s=10, alpha=0.7, label=str(cls))

plt.legend()
plt.title("Visualization of Weigted-BERT Embeddings")
plt.show()

"""---

# Weighted Focal Loss
"""

bert_model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=5).to(device)

# hyperparameters
epochs = 3
learning_rate = 2e-6
epsilon = 1e-8
warmup_ratio = 0.1

# steps
t_total = len(train_loader) * epochs
warmup_steps = int(t_total * warmup_ratio)

# optimizer
optimizer = AdamW(bert_model.parameters(),lr=learning_rate,eps=epsilon)

# shceduler
scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=warmup_steps,
    num_training_steps=t_total
)

print(f"Total steps: {t_total}, Warmup steps: {warmup_steps}")

import torch.nn.functional as F

class WeightedFocalLoss(nn.Module):
    def __init__(self, class_weights=None, gamma=1):
        super().__init__()
        self.class_weights = class_weights
        self.gamma = gamma

    def forward(self, logits, labels):
        ce_loss = F.cross_entropy(logits, labels, weight=self.class_weights, reduction='none')
        probs = F.softmax(logits, dim=1)
        pt = probs.gather(1, labels.unsqueeze(1)).squeeze()  # get probability of true label

        # compute focal factor
        focal_factor = (1 - pt) ** self.gamma

        # compute focal loss
        loss = focal_factor * ce_loss
        return loss.mean()

# define weighted focal loss function
criterion = WeightedFocalLoss(class_weights=class_weights, gamma=1)

# send model to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bert_model.to(device)

for epoch in range(epochs):
    bert_model.train()
    total_loss = 0.0

    # show progress bar
    progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}", leave=True)

    for step, batch in enumerate(progress_bar):
        optimizer.zero_grad()

        # send to GPU
        batch = tuple(t.to(device) for t in batch)
        input_ids, attention_mask, labels = batch

        # forward propagation
        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits if hasattr(outputs, "logits") else outputs[1]

        # compute loss with class-balanced CE
        loss = criterion(logits, labels)
        total_loss += loss.item()

        # backward propagation
        loss.backward()

        # clip gradients
        clip_grad_norm_(bert_model.parameters(), max_norm=1.0)

        # update parameters and scheduler
        optimizer.step()
        scheduler.step()

        # update progress bar
        if step % 50 == 0:
            progress_bar.set_postfix({"Batch Loss": f"{loss.item():.4f}"})

    # calculate average loss
    avg_epoch_loss = total_loss / len(train_loader)
    print(f"\nEpoch {epoch+1}/{epochs} | Average Training Loss: {avg_epoch_loss:.4f}\n")

# save the model
output_dir = "outputs/bert_weighted_focal_loss"
bert_model.save_pretrained(output_dir)
tokenizer.save_pretrained(output_dir)

model_path = "outputs/bert_weighted_focal_loss"

bert_model = BertForSequenceClassification.from_pretrained(model_path).to(device)
tokenizer = BertTokenizer.from_pretrained(model_path)

y_true, y_pred, y_pred_proba = validation(bert_model, val_loader, device)

print("Accuracy:", accuracy_score(y_true, y_pred))
print(classification_report(y_true, y_pred))

embeddings, labels = extract_embeddings(bert_model, val_loader, device)

pca = PCA(n_components=50).fit_transform(embeddings)

umap_weightedCE = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1).fit_transform(pca)

plt.figure(figsize=(10,10))

for cls in np.unique(labels):
    idx = labels == cls
    plt.scatter(umap_weightedCE[idx,0], umap_weightedCE[idx,1], s=10, alpha=0.7, label=str(cls))

plt.legend()
plt.title("Visualization of Weigted-BERT Embeddings")
plt.show()