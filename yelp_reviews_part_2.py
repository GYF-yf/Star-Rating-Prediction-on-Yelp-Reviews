# -*- coding: utf-8 -*-
"""Yelp_Reviews_Part_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_q0lFo3exB9o1_ET583KeB-ZqalPKMC9

# Preparation
"""

from google.colab import drive
drive.mount("/content/drive")

# suppress warnings
import warnings;
warnings.filterwarnings("ignore");

# common imports
import pandas as pd
import numpy as np
import re
import glob
import os
import sys
import json
import pprint as pp
import html
import nltk

from tqdm.auto import tqdm
# register pandas
tqdm.pandas()

import matplotlib
from matplotlib import pyplot as plt

import seaborn as sns
sns.set_style("darkgrid")

pd.set_option('display.max_colwidth',None)

# change to current directory
BASE_DIR = "/content/drive/MyDrive/"
os.chdir(BASE_DIR)

path = "./df_yelp_reviews.pkl"
df = pd.read_pickle(path)

df.head()

df.shape

"""# Examples of reviews

## 1-star reviews samples
"""

df_1 = df[df['stars']==1].drop(columns=['length','tokens','num_of_tokens']).sample(20,random_state=42)
df_1

"""## 2-star reviews samples"""

df_2 = df[df['stars']==2].drop(columns=['length','tokens','num_of_tokens']).sample(20,random_state=42)
df_2

"""## 3-star reviews samples"""

df_3 = df[df['stars']==3].drop(columns=['length','tokens','num_of_tokens']).sample(20,random_state=42)
df_3

"""# DeBERTa

## Load DeBERTa-v3-large
"""

pip install transformers

from transformers import AutoTokenizer, AutoModelForSequenceClassification

# load tokenizer and model from transformers

tokenizer = AutoTokenizer.from_pretrained("microsoft/deberta-v3-large")
bert_model= AutoModelForSequenceClassification.from_pretrained("microsoft/deberta-v3-large",num_labels=5)

"""## Train-Val-Test Split"""

# prepare test dataset, which accounts for 10%
from sklearn.model_selection import train_test_split

X_train_original, X_test, y_train_original, y_test = train_test_split(
              df['text'].astype(str),
              df['stars'],
              test_size=0.2,
              random_state=42,
              stratify=df['stars'])

# get training and validation datasets

X_train, X_val, y_train, y_val = train_test_split(
    X_train_original,
    y_train_original,
    test_size=0.1,
    random_state=42,
    stratify=y_train_original)

"""## Embeddings"""

# define a function to get embeddings

def get_tokens(texts, tokenizer, max_len=128):

    return tokenizer(
        texts,
        padding="max_length",       # pad to the max length
        truncation=True,            # truncate extra long text
        max_length=max_len,
        return_tensors="pt"         # return tensors
    )

train_embedding = get_tokens(X_train.astype(str).tolist(), tokenizer, max_len=128)
val_embedding = get_tokens(X_val.astype(str).tolist(), tokenizer, max_len=128)
test_embedding  = get_tokens(X_test.astype(str).tolist(), tokenizer, max_len=128)

"""## Dataset & DataLoader"""

import torch
from torch.utils.data import TensorDataset, DataLoader
from sklearn.preprocessing import LabelEncoder

# encode labels
encoder = LabelEncoder()
y_train_encode = encoder.fit_transform(y_train)
y_val_encode = encoder.transform(y_val)
y_test_encode = encoder.transform(y_test)

# build datasets

train_dataset = TensorDataset(
    train_embedding['input_ids'],
    train_embedding['attention_mask'],
    torch.tensor(y_train_encode)
)

val_dataset = TensorDataset(
    val_embedding['input_ids'],
    val_embedding['attention_mask'],
    torch.tensor(y_val_encode)
)

test_dataset = TensorDataset(
    test_embedding['input_ids'],
    test_embedding['attention_mask'],
    torch.tensor(y_test_encode))

# DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)
test_loader = DataLoader(test_dataset, batch_size=16)

"""## Optimizer & Scheduler"""

from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup

# hyperparameters
epochs = 3
learning_rate = 2e-6
epsilon = 1e-8
warmup_ratio = 0.1

# steps
t_total = len(train_loader) * epochs
warmup_steps = int(t_total * warmup_ratio)

# optimizer
optimizer = AdamW(bert_model.parameters(),lr=learning_rate,eps=epsilon)

# shceduler
scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=warmup_steps,
    num_training_steps=t_total
)

print(f"Total steps: {t_total}, Warmup steps: {warmup_steps}")

"""## Training"""

from tqdm.notebook import tqdm
from tqdm import trange
from torch.nn.utils import clip_grad_norm_

# send to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bert_model.to(device)

for epoch in trange(epochs):
    bert_model.train()
    total_loss = 0.0

    # show the progress bar
    progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}", leave=True)

    for step, batch in enumerate(progress_bar):
        optimizer.zero_grad()

        # send to GPU
        batch = tuple(t.to(device) for t in batch)

        inputs = {
            'input_ids': batch[0],
            'attention_mask': batch[1],
            'labels': batch[2]
        }

        # forward propagation
        outputs = bert_model(**inputs)
        loss = outputs.loss

        # back propagation
        loss.backward()

        # clip gradients
        clip_grad_norm_(bert_model.parameters(), max_norm=1.0)

        # update parameters
        optimizer.step()

        # update scheduler
        scheduler.step()

        # calculate total loss
        total_loss += loss.item()

        # update progress bar
        progress_bar.set_postfix({"Batch Loss": f"{loss.item():.4f}"})

    # calculate average loss and show
    avg_epoch_loss = total_loss / len(train_loader)
    print(f"\nEpoch {epoch+1} | Average Training Loss: {avg_epoch_loss:.4f}")

# save the model
output_dir = "outputs/deberta-v3-large"
tokenizer.save_pretrained(output_dir)
bert_model.save_pretrained(output_dir)

"""## Validation"""

# define a validation function

def validation(model, dataloader, device):
    model.eval()

    preds = []
    probs = []
    labels = []

    with torch.no_grad():
        for batch in dataloader:
            batch = [t.to(device) for t in batch]
            inputs = {
                'input_ids': batch[0],
                'attention_mask': batch[1]
            }
            outputs = model(**inputs)

            logits = outputs.logits
            prob = torch.softmax(logits, dim=1)

            probs.append(prob.cpu().numpy())
            preds.append(torch.argmax(prob, dim=1).cpu().numpy())
            labels.append(batch[2].cpu().numpy())

    return (
        np.concatenate(labels),
        np.concatenate(preds),
        np.concatenate(probs),
    )

# load the model and validate

from transformers import DebertaV2ForSequenceClassification,DebertaV2Tokenizer
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, precision_recall_curve, f1_score, confusion_matrix, average_precision_score
from sklearn.preprocessing import label_binarize

model_path = "outputs/deberta-v3-large"
bert_model = DebertaV2ForSequenceClassification.from_pretrained("outputs/deberta-v3-large").to(device)
tokenizer = DebertaV2Tokenizer.from_pretrained("outputs/deberta-v3-large")

# validation
y_true, y_pred, y_pred_proba = validation(bert_model, val_loader, device)

print("Accuracy:", accuracy_score(y_true, y_pred))
print(classification_report(y_true, y_pred))

print(confusion_matrix(y_true, y_pred))

classes = sorted(np.unique(y_true))
y_val_bin = label_binarize(y_true, classes=classes)
n_classes = len(classes)

def plot_roc_auc(y_test_bin, y_pred_proba,classes):

  for i in range(n_classes):
      class_label = classes[i]

      # ROC-AUC curve
      fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
      roc_auc = auc(fpr, tpr)

      plt.figure(figsize=(5,5))
      plt.plot(fpr, tpr, label=f"ROC-AUC = {roc_auc:.4f}")
      plt.plot([0, 1], [0, 1], 'k--')
      plt.xlabel("False Positive Rate")
      plt.ylabel("True Positive Rate")
      plt.title(f"ROC-AUC Curve - Class {class_label}")
      plt.legend()
      plt.show()

# show PR-AUC curve

def plot_pr_auc(y_test_bin, y_pred_proba,classes):

  for i in range(n_classes):
      class_label = classes[i]

      precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_pred_proba[:, i])
      pr_auc = auc(recall, precision)

      plt.figure(figsize=(5,5))
      plt.plot(recall, precision, label=f"PR-AUC = {pr_auc:.4f}")
      plt.xlabel("Recall")
      plt.ylabel("Precision")
      plt.title(f"PR-AUC Curve - Class {class_label}")
      plt.legend()
      plt.show()

plot_roc_auc(y_val_bin, y_pred_proba, classes)

plot_pr_auc(y_val_bin, y_pred_proba, classes)

# calculate overall PR-AUC score

print('PR-AUC Score: ', average_precision_score(y_val_bin,y_pred_proba,average='macro'))

from sklearn.metrics import roc_auc_score

print('ROC-AUC Score:', roc_auc_score(y_true, y_pred_proba, multi_class='ovr'))

# find the best threshold for each class

def find_best_thresholds(y_test_bin, y_pred_proba, classes):

    best_thresholds = {}

    for i in range(n_classes):
        precision, recall, thresholds = precision_recall_curve(y_test_bin[:, i], y_pred_proba[:, i])

        f1 = 2 * precision * recall / (precision + recall + 1e-8)
        best_idx = np.argmax(f1)

        best_threshold = thresholds[best_idx]
        best_thresholds[classes[i]] = best_threshold

        print(f"Class {classes[i]} | best threshold = {best_threshold:.4f} | F1={f1[best_idx]:.4f}")

    return best_thresholds

# set new logic for prediction

def predict(y_pred_proba, thresholds, classes):
    preds = []
    for row in y_pred_proba:
        result = []

        # find classes >= threshold
        for i, cls in enumerate(classes):
            if row[i] >= thresholds[cls]:
                result.append((cls, row[i]))

        # otherwise, use argmax
        if len(result) == 0:
            preds.append(classes[np.argmax(row)])

        # if more classes, choose the max one
        else:
            preds.append(max(result, key=lambda x: x[1])[0])

    return np.array(preds)

best_thresholds = find_best_thresholds(y_val_bin, y_pred_proba, classes)

y_pred_new = predict(y_pred_proba, best_thresholds, classes)

print("New Accuracy:", accuracy_score(y_true, y_pred_new))
print(classification_report(y_true, y_pred_new))

# define a function to extract embeddings for visualization

def extract_embeddings(model, dataloader, device):
    model.eval()
    embeddings = []
    labels = []

    with torch.no_grad():
        for batch in dataloader:
            batch = [t.to(device) for t in batch]
            input_ids, attention_mask, label = batch

            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                output_hidden_states=True
            )

            # choose the CLS of the final layer
            last_hidden = outputs.hidden_states[-1]
            cls_emb = last_hidden[:, 0, :].cpu().numpy()

            embeddings.append(cls_emb)
            labels.append(label.cpu().numpy())

    embeddings = np.concatenate(embeddings, axis=0)
    labels = np.concatenate(labels, axis=0)

    return embeddings, labels

embeddings, labels = extract_embeddings(bert_model, val_loader, device)

print('Embeddings: ',embeddings.shape)
print('Labels: ',labels.shape)

# use PCA to reduce dimension firstly, because current dimension is 768, very high

from sklearn.decomposition import PCA

pca_ce = PCA(n_components=50).fit_transform(embeddings)

# use UMAP to reduce to 2 dimensions

import umap.umap_ as umap

umap_ce = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1).fit_transform(pca_ce)

plt.figure(figsize=(10,10))

for cls in np.unique(labels):
    idx = labels == cls
    plt.scatter(umap_ce[idx,0], umap_ce[idx,1], s=10, alpha=0.7, label=str(cls))

plt.legend()
plt.title("Visualization of BERT Embeddings")
plt.show()















"""## Testing"""

# also define a test function

def test(model, dataloader, device):
    model.eval()
    preds, labels = [], []

    for batch in tqdm(dataloader, desc="Testing"):
        batch = [t.to(device) for t in batch]

        with torch.no_grad():
            # no need for labels
            outputs = model(
                input_ids=batch[0],
                attention_mask=batch[1]
            )

            logits = outputs.logits

            # get predictions
            preds.append(torch.argmax(logits, dim=1).detach().cpu().numpy())
            labels.append(batch[2].detach().cpu().numpy())

    # concatenate
    preds = np.concatenate(preds, axis=0)
    labels = np.concatenate(labels, axis=0)

    # results
    accuracy = accuracy_score(labels, preds)
    f1 = f1_score(labels, preds, average='macro')

    print(f"\nTest Accuracy: {accuracy:.4f}")
    print(f"Test F1-score: {f1:.4f}")
    print("\nClassification Report:\n", classification_report(labels, preds))

    return accuracy, f1

test_accuracy, test_f1 = test(bert_model, test_loader, device)